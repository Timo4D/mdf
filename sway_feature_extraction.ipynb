{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb146478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sway_utils.metrics as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7ba41d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FPS = 30.0  # Kinect is 30 Hz\n",
    "\n",
    "\n",
    "def compute_sway_metrics_from_paths(ml_raw, ap_raw, fs: float = FPS):\n",
    "    \"\"\"\n",
    "    Replicates the logic of calculate_sway_from_recording() for Kinect,\n",
    "    but for a plain ML/AP time series and WITHOUT plotting.\n",
    "\n",
    "    ml_raw, ap_raw: np.array of CoM in *cm* (as in the example code).\n",
    "    \"\"\"\n",
    "    ml_raw = np.asarray(ml_raw, dtype=float)\n",
    "    ap_raw = np.asarray(ap_raw, dtype=float)\n",
    "\n",
    "    # 1) Filter signal like calculate_RD() does for Kinect\n",
    "    #    Note: fc=8 in that function.\n",
    "    ml_filt, ap_filt = sm.filter_signal(ml_raw, ap_raw, fc=8, fs=fs)\n",
    "\n",
    "    # 2) Mean-centred absolute deviations (same as ML/AP in calculate_RD)\n",
    "    mean_ml = np.mean(ml_filt)\n",
    "    mean_ap = np.mean(ap_filt)\n",
    "\n",
    "    ML = np.abs(ml_filt - mean_ml)\n",
    "    AP = np.abs(ap_filt - mean_ap)\n",
    "    RD = np.sqrt(ML**2 + AP**2)\n",
    "\n",
    "    recording_length = len(RD)\n",
    "    if recording_length == 0:\n",
    "        raise ValueError(\"Empty ML/AP series\")\n",
    "\n",
    "    # 3) MDIST and RDIST (identical formulas)\n",
    "    MDIST_ML = np.sum(ML) / recording_length\n",
    "    MDIST_AP = np.sum(AP) / recording_length\n",
    "    MDIST = np.sum(RD) / recording_length\n",
    "\n",
    "    RDIST_ML = np.sqrt(np.sum(ML**2) / recording_length)\n",
    "    RDIST_AP = np.sqrt(np.sum(AP**2) / recording_length)\n",
    "    RDIST = np.sqrt(np.sum(RD**2) / recording_length)\n",
    "\n",
    "    # 4) TOTEX and fractal dimension (reusing original function)\n",
    "    TOTEX_ML, TOTEX_AP, TOTEX, FD = sm.calculate_TOTEX(ML, AP)\n",
    "\n",
    "    # 5) Mean velocity (Kinect → 30 Hz)\n",
    "    T = recording_length / fs\n",
    "    MVELO_ML = TOTEX_ML / T\n",
    "    MVELO_AP = TOTEX_AP / T\n",
    "    MVELO = TOTEX / T\n",
    "\n",
    "    # 6) Mean frequency (same as in calculate_sway_from_recording)\n",
    "    MFREQ_ML = MVELO_ML / (4 * (np.sqrt(2 * MDIST_ML))) if MDIST_ML > 0 else 0.0\n",
    "    MFREQ_AP = MVELO_AP / (4 * (np.sqrt(2 * MDIST_AP))) if MDIST_AP > 0 else 0.0\n",
    "    MFREQ = MVELO / (2 * np.pi * MDIST) if MDIST > 0 else 0.0\n",
    "\n",
    "    # 7) AREA_CE – use the same confidence_ellipse function, but without adding to axes\n",
    "    #    The function signature is: confidence_ellipse(x, y, ax, ..., return_ellipse=True/False)\n",
    "    #    With return_ellipse=False it returns: height, width, area, angle\n",
    "    height, width, AREA_CE, angle = sm.confidence_ellipse(\n",
    "        ml_filt,\n",
    "        ap_filt,\n",
    "        ax=None,\n",
    "        n_std=1.96,\n",
    "        return_ellipse=False,\n",
    "        edgecolor=\"red\",\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"RDIST_ML\": RDIST_ML,\n",
    "        \"RDIST_AP\": RDIST_AP,\n",
    "        \"RDIST\": RDIST,\n",
    "        \"MDIST_ML\": MDIST_ML,\n",
    "        \"MDIST_AP\": MDIST_AP,\n",
    "        \"MDIST\": MDIST,\n",
    "        \"TOTEX_ML\": TOTEX_ML,\n",
    "        \"TOTEX_AP\": TOTEX_AP,\n",
    "        \"TOTEX\": TOTEX,\n",
    "        \"MVELO_ML\": MVELO_ML,\n",
    "        \"MVELO_AP\": MVELO_AP,\n",
    "        \"MVELO\": MVELO,\n",
    "        \"MFREQ_ML\": MFREQ_ML,\n",
    "        \"MFREQ_AP\": MFREQ_AP,\n",
    "        \"MFREQ\": MFREQ,\n",
    "        \"AREA_CE\": AREA_CE,\n",
    "        \"FRAC_DIM\": FD,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4581c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sway_utils.recordings import KinectRecording\n",
    "\n",
    "def extract_sway_for_kinect_recording(\n",
    "    base_dir: str,\n",
    "    part_id: int,\n",
    "    movement_folder: str,\n",
    "    movement_label: str,\n",
    "    start_frame: int = 200,\n",
    "    end_frame: int = 500,\n",
    "    com_joint_index: int = 25,\n",
    ") -> dict | None:\n",
    "    \"\"\"\n",
    "    For a given participant & movement, load the KinectRecording,\n",
    "    extract CoM from joint #25, and compute sway metrics.\n",
    "\n",
    "    Returns: dict with metrics + identifiers, or None if something is missing.\n",
    "    \"\"\"\n",
    "    str_part = str(part_id)\n",
    "\n",
    "    skel_root_path = os.path.join(\n",
    "        base_dir,\n",
    "        str_part,\n",
    "        f\"{str_part}_{movement_folder}\",\n",
    "        \"skel\",\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(skel_root_path):\n",
    "        print(f\"[WARN] skeleton path not found: {skel_root_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        recording = KinectRecording(\n",
    "            skel_root_path,\n",
    "            \"\",                 # depth path not needed for sway\n",
    "            movement_label,     # just a label, used by the class\n",
    "            part_id,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] failed to load KinectRecording for {skel_root_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    xyz = recording.stacked_filtered_XYZ_values  # shape [3, 26, frames] usually\n",
    "    if xyz is None:\n",
    "        print(f\"[WARN] no filtered XYZ values for {skel_root_path}\")\n",
    "        return None\n",
    "\n",
    "    n_frames = xyz.shape[2]\n",
    "    start = max(0, start_frame)\n",
    "    end = min(n_frames, end_frame)\n",
    "    if end <= start + 1:\n",
    "        print(f\"[WARN] not enough frames ({n_frames}) for {skel_root_path}\")\n",
    "        return None\n",
    "\n",
    "    # CoM in cm (as in the demo code)\n",
    "    ml_raw = xyz[0, com_joint_index, start:end] * 100.0  # ML (x)\n",
    "    ap_raw = xyz[2, com_joint_index, start:end] * 100.0  # AP (z)\n",
    "\n",
    "    metrics = compute_sway_metrics_from_paths(ml_raw, ap_raw, fs=FPS)\n",
    "\n",
    "    # Add identifiers\n",
    "    metrics[\"part_id\"] = part_id\n",
    "    metrics[\"movement\"] = movement_label\n",
    "    metrics[\"start_frame\"] = start\n",
    "    metrics[\"end_frame\"] = end\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2203e8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RDIST_ML': np.float64(0.16574902168413605), 'RDIST_AP': np.float64(0.1754042084355947), 'RDIST': np.float64(0.24132835416951268), 'MDIST_ML': np.float64(0.1295965032064326), 'MDIST_AP': np.float64(0.15620486277413861), 'MDIST': np.float64(0.2208600322118884), 'TOTEX_ML': np.float64(2.3367624833042746), 'TOTEX_AP': np.float64(2.3820361433601724), 'TOTEX': np.float64(3.7371118445647262), 'MVELO_ML': np.float64(0.23367624833042747), 'MVELO_AP': np.float64(0.23820361433601725), 'MVELO': np.float64(0.3737111844564726), 'MFREQ_ML': np.float64(0.11474742289413078), 'MFREQ_AP': np.float64(0.10654328495845933), 'MFREQ': np.float64(0.2693017007165552), 'AREA_CE': np.float64(0.4618488631840259), 'FRAC_DIM': np.float64(3.81147461177036), 'part_id': 25, 'movement': 'Quiet-Standing-Eyes-Open', 'start_frame': 200, 'end_frame': 500}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "BASE = \"data/sample_set\"\n",
    "\n",
    "row = extract_sway_for_kinect_recording(\n",
    "    base_dir=BASE,\n",
    "    part_id=25,\n",
    "    movement_folder=\"Quiet-Standing-Eyes-Open\",\n",
    "    movement_label=\"Quiet-Standing-Eyes-Open\",\n",
    ")\n",
    "\n",
    "print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ba9081a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] skeleton path not found: /home/timo/mdf/data/kinecal/7/7_Quiet-Standing-Eyes-Open/skel\n",
      "[WARN] skeleton path not found: /home/timo/mdf/data/kinecal/11/11_Quiet-Standing-Eyes-Open/skel\n",
      "[WARN] skeleton path not found: /home/timo/mdf/data/kinecal/11/11_Quiet-Standing-Eyes-Closed/skel\n",
      "[WARN] skeleton path not found: /home/timo/mdf/data/kinecal/21/21_Quiet-Standing-Eyes-Closed/skel\n",
      "[WARN] skeleton path not found: /home/timo/mdf/data/kinecal/23/23_Quiet-Standing-Eyes-Open/skel\n",
      "[WARN] skeleton path not found: /home/timo/mdf/data/kinecal/201/201_Quiet-Standing-Eyes-Closed/skel\n",
      "[WARN] skeleton path not found: /home/timo/mdf/data/kinecal/307/307_Quiet-Standing-Eyes-Open/skel\n",
      "[WARN] skeleton path not found: /home/timo/mdf/data/kinecal/312/312_Quiet-Standing-Eyes-Open/skel\n",
      "   RDIST_ML  RDIST_AP     RDIST  MDIST_ML  MDIST_AP     MDIST  TOTEX_ML  \\\n",
      "0  0.033524  0.272334  0.274389  0.028560  0.236129  0.239285  0.990356   \n",
      "1  0.129893  0.322521  0.347696  0.122723  0.273363  0.316428  0.878940   \n",
      "2  0.326222  0.568981  0.655866  0.282798  0.515176  0.621031  4.272672   \n",
      "3  0.827491  0.586316  1.014154  0.712415  0.497422  0.914730  8.706480   \n",
      "4  0.077170  0.236320  0.248601  0.062525  0.176779  0.197308  1.269195   \n",
      "\n",
      "   TOTEX_AP      TOTEX  MVELO_ML  ...  end_frame  group  age  sex  height  \\\n",
      "0  1.859197   2.260934  0.099036  ...        500     HA   54    0    1.82   \n",
      "1  3.646805   3.858272  0.087894  ...        500     HA   54    0    1.82   \n",
      "2  6.627905   8.646276  0.427267  ...        500    FHm   71    0    1.80   \n",
      "3  5.708795  11.232685  0.870648  ...        500    FHm   71    0    1.80   \n",
      "4  2.954501   3.467400  0.126919  ...        500     HA   38    0    1.75   \n",
      "\n",
      "   weight   BMI  recorded_in_the_lab clinically_at_risk  is_faller  \n",
      "0    73.0  22.0                    1                  0          0  \n",
      "1    73.0  22.0                    1                  0          0  \n",
      "2    81.6  25.2                    1                  0          1  \n",
      "3    81.6  25.2                    1                  0          1  \n",
      "4    80.0  26.1                    1                  0          0  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Config ---\n",
    "BASE = \"/home/timo/mdf/data/kinecal\"      # or full kinecal root later\n",
    "REGISTER_CSV = \"data/register_processed.csv\"      # adjust path as needed\n",
    "\n",
    "MOVEMENTS = [\n",
    "    {\n",
    "        \"folder\": \"Quiet-Standing-Eyes-Open\",\n",
    "        \"label\": \"Quiet-Standing-Eyes-Open\",\n",
    "        \"start_frame\": 200,\n",
    "        \"end_frame\": 500,\n",
    "    },\n",
    "    {\n",
    "        \"folder\": \"Quiet-Standing-Eyes-Closed\",\n",
    "        \"label\": \"Quiet-Standing-Eyes-Closed\",\n",
    "        \"start_frame\": 200,\n",
    "        \"end_frame\": 500,\n",
    "    },\n",
    "    # you can add more movements here:\n",
    "    # {\n",
    "    #     \"folder\": \"Quiet-Standing-Eyes-Closed\",\n",
    "    #     \"label\": \"Quiet-Standing-Eyes-Closed\",\n",
    "    #     \"start_frame\": 200,\n",
    "    #     \"end_frame\": 500,\n",
    "    # },\n",
    "]\n",
    "\n",
    "# --- Load participant registry ---\n",
    "reg = pd.read_csv(REGISTER_CSV)\n",
    "reg = reg.loc[:, ~reg.columns.str.startswith(\"Unnamed\")]  # drop stray cols\n",
    "\n",
    "# binary faller label from your group distribution\n",
    "reg[\"is_faller\"] = reg[\"group\"].isin([\"FHs\", \"FHm\"]).astype(int)\n",
    "\n",
    "rows = []\n",
    "\n",
    "for _, r in reg.iterrows():\n",
    "    part_id = int(r[\"part_id\"])\n",
    "\n",
    "    for mv in MOVEMENTS:\n",
    "        metrics = extract_sway_for_kinect_recording(\n",
    "            base_dir=BASE,\n",
    "            part_id=part_id,\n",
    "            movement_folder=mv[\"folder\"],\n",
    "            movement_label=mv[\"label\"],\n",
    "            start_frame=mv[\"start_frame\"],\n",
    "            end_frame=mv[\"end_frame\"],\n",
    "        )\n",
    "        if metrics is None:\n",
    "            continue\n",
    "\n",
    "        # attach labels & demographics\n",
    "        metrics[\"group\"] = r[\"group\"]\n",
    "        metrics[\"age\"] = r[\"age\"]\n",
    "        metrics[\"sex\"] = r[\"sex\"]\n",
    "        metrics[\"height\"] = r[\"height\"]\n",
    "        metrics[\"weight\"] = r[\"weight\"]\n",
    "        metrics[\"BMI\"] = r[\"BMI\"]\n",
    "        metrics[\"recorded_in_the_lab\"] = r[\"recorded_in_the_lab\"]\n",
    "        metrics[\"clinically_at_risk\"] = r[\"clinically-at-risk\"]\n",
    "        metrics[\"is_faller\"] = r[\"is_faller\"]\n",
    "\n",
    "        rows.append(metrics)\n",
    "\n",
    "features_df = pd.DataFrame(rows)\n",
    "print(features_df.head())\n",
    "\n",
    "# Save for later use in ML\n",
    "features_df.to_csv(\"kinecal_sway_features_custom_window.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8b41e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
